import sensor
import image
import time
import gc
import math
import lcd  # æ·»åŠ LCDæ¨¡å—
from pyb import LED
from pyb import UART

red_led = LED(1)
green_led = LED(2)
blue_led = LED(3)

# åˆå§‹åŒ–UARTé€šä¿¡
uart = UART(2, 9600, timeout_char=200)

# å¼ºåˆ¶æ¸…ç†å†…å­˜
gc.collect()

# åˆå§‹åŒ–æ‘„åƒå¤´
sensor.reset()
sensor.set_pixformat(sensor.RGB565)  # æ”¹ä¸ºRGB565ä»¥æ”¯æŒLCDå½©è‰²æ˜¾ç¤º
sensor.set_framesize(sensor.QVGA)
sensor.set_contrast(2)
sensor.set_brightness(0)
sensor.set_gainceiling(8)
sensor.skip_frames(time=1000)
sensor.set_auto_gain(True)
sensor.set_auto_whitebal(True)
sensor.set_hmirror(True)
#sensor.set_vflip(True)

# åˆå§‹åŒ–LCD
lcd.init()

# åŠ è½½äººè„¸çº§è”æ¨¡å‹
face_cascade = image.HaarCascade("frontalface", stages=20)

# å­˜å‚¨ç”¨æˆ·äººè„¸ä¿¡æ¯
user_faces = []

# é…ç½®å‚æ•°
num_users_to_enroll = 1
faces_per_user = 6  # é€‚ä¸­çš„æ ·æœ¬æ•°é‡
print("å‡†å¤‡å½•å…¥", num_users_to_enroll, "ä½ç”¨æˆ·çš„äººè„¸ï¼Œæ¯äººæ‹æ‘„", faces_per_user, "å¼ ç…§ç‰‡")

def preprocess_face(face_roi):
    """æ¸©å’Œçš„äººè„¸é¢„å¤„ç†"""
    try:
        # è½¬æ¢ä¸ºç°åº¦è¿›è¡Œå¤„ç†
        if face_roi.format() == sensor.RGB565:
            face_roi = face_roi.to_grayscale()

        # ç›´æ–¹å›¾å‡è¡¡åŒ–å¢å¼ºå¯¹æ¯”åº¦
        face_roi.histeq()

        # è½»å¾®é™å™ª
        face_roi.gaussian(1)

        return face_roi
    except Exception as e:
        print(f"é¢„å¤„ç†å¤±è´¥: {e}")
        return face_roi

def extract_stable_lbp_features(face_roi, radius=1, neighbors=8):
    """ç¨³å®šçš„LBPç‰¹å¾æå–"""
    try:
        # ç¡®ä¿æ˜¯ç°åº¦å›¾åƒ
        if face_roi.format() == sensor.RGB565:
            face_roi = face_roi.to_grayscale()

        width = face_roi.width()
        height = face_roi.height()

        if width < 24 or height < 24:
            return None

        # LBPæ¨¡å¼åç§»é‡
        offsets = []
        for i in range(neighbors):
            angle = 2 * math.pi * i / neighbors
            dx = int(radius * math.cos(angle))
            dy = int(radius * math.sin(angle))
            offsets.append((dx, dy))

        # æ›´å¤§çš„äººè„¸åŒºåŸŸåˆ’åˆ†ï¼Œå¢åŠ ç¨³å®šæ€§
        regions = [
            (0.1, 0.1, 0.5, 0.5, "å·¦ä¸Š"),     # å·¦ä¸Šï¼ˆåŒ…å«å·¦çœ¼ï¼‰
            (0.5, 0.1, 0.9, 0.5, "å³ä¸Š"),     # å³ä¸Šï¼ˆåŒ…å«å³çœ¼ï¼‰
            (0.2, 0.3, 0.8, 0.7, "ä¸­å¤®"),     # ä¸­å¤®ï¼ˆé¼»å­åŒºåŸŸï¼‰
            (0.2, 0.6, 0.8, 0.95, "ä¸‹éƒ¨"),    # ä¸‹éƒ¨ï¼ˆå˜´éƒ¨åŒºåŸŸï¼‰
        ]

        all_features = []

        for x_start_r, y_start_r, x_end_r, y_end_r, region_name in regions:
            x_start = int(width * x_start_r)
            y_start = int(height * y_start_r)
            x_end = int(width * x_end_r)
            y_end = int(height * y_end_r)

            # LBPç›´æ–¹å›¾
            lbp_hist = [0] * 256
            total_pixels = 0

            # é€‚å½“çš„é‡‡æ ·å¯†åº¦
            step = max(1, (x_end - x_start) // 12)

            for y in range(y_start + radius, y_end - radius, step):
                for x in range(x_start + radius, x_end - radius, step):
                    try:
                        center_pixel = face_roi.get_pixel(x, y)
                        if isinstance(center_pixel, tuple):
                            center_pixel = sum(center_pixel) // len(center_pixel)

                        lbp_value = 0
                        valid_neighbors = 0

                        for i, (dx, dy) in enumerate(offsets):
                            nx, ny = x + dx, y + dy
                            if 0 <= nx < width and 0 <= ny < height:
                                neighbor_pixel = face_roi.get_pixel(nx, ny)
                                if isinstance(neighbor_pixel, tuple):
                                    neighbor_pixel = sum(neighbor_pixel) // len(neighbor_pixel)

                                if neighbor_pixel >= center_pixel:
                                    lbp_value |= (1 << i)
                                valid_neighbors += 1

                        if valid_neighbors == neighbors:
                            lbp_hist[lbp_value] += 1
                            total_pixels += 1

                    except:
                        pass

            # é€‰æ‹©æ›´æœ‰åŒºåˆ†æ€§çš„LBPæ¨¡å¼
            if total_pixels > 0:
                # å‡åŒ€æ¨¡å¼ + ä¸€äº›é‡è¦çš„éå‡åŒ€æ¨¡å¼
                important_patterns = [
                    0, 1, 3, 7, 15, 31, 63, 127, 255,  # å‡åŒ€æ¨¡å¼
                    2, 4, 6, 8, 12, 14, 16, 24, 28, 30,  # é‡è¦éå‡åŒ€æ¨¡å¼
                    32, 48, 56, 60, 62, 64, 96, 112, 120, 124
                ]

                region_features = []
                for pattern in important_patterns[:16]:  # å–å‰16ä¸ªæ¨¡å¼
                    normalized_value = (lbp_hist[pattern] * 100) // total_pixels  # é™ä½å½’ä¸€åŒ–ç³»æ•°
                    region_features.append(min(255, normalized_value))

                all_features.extend(region_features)
            else:
                all_features.extend([0] * 16)

        return all_features

    except Exception as e:
        print(f"LBPç‰¹å¾æå–å¤±è´¥: {e}")
        return None

def extract_simple_features(face_roi):
    """ç®€åŒ–ä½†ç¨³å®šçš„ç‰¹å¾æå–"""
    try:
        # é¢„å¤„ç†
        face_roi = preprocess_face(face_roi)

        width = face_roi.width()
        height = face_roi.height()

        if width < 24 or height < 24:
            return None

        all_features = []

        # 1. LBPç‰¹å¾ï¼ˆä¸»è¦ï¼‰
        lbp_features = extract_stable_lbp_features(face_roi)
        if lbp_features:
            all_features.extend(lbp_features)

        # 2. ç®€åŒ–çš„ç½‘æ ¼ç»Ÿè®¡ç‰¹å¾
        grid_size = 6  # é™ä½ç½‘æ ¼å¤§å°
        cell_w = width // grid_size
        cell_h = height // grid_size

        for i in range(grid_size):
            for j in range(grid_size):
                x_start = i * cell_w
                y_start = j * cell_h
                x_end = min(x_start + cell_w, width)
                y_end = min(y_start + cell_h, height)

                # è®¡ç®—è¯¥ç½‘æ ¼çš„å¹³å‡ç°åº¦
                pixel_sum = 0
                pixel_count = 0

                for y in range(y_start, y_end, 2):
                    for x in range(x_start, x_end, 2):
                        try:
                            pixel = face_roi.get_pixel(x, y)
                            if isinstance(pixel, tuple):
                                pixel = sum(pixel) // len(pixel)
                            pixel_sum += pixel
                            pixel_count += 1
                        except:
                            pass

                if pixel_count > 0:
                    avg_gray = pixel_sum // pixel_count
                    all_features.append(avg_gray)
                else:
                    all_features.append(128)  # é»˜è®¤ä¸­ç­‰ç°åº¦

        # åªå–éƒ¨åˆ†ç½‘æ ¼ç‰¹å¾é¿å…è¿‡æ‹Ÿåˆ
        all_features = all_features[:80]  # LBP(64) + éƒ¨åˆ†ç½‘æ ¼ç‰¹å¾(16)

        print(f"ç‰¹å¾ç»´åº¦: {len(all_features)}")
        return all_features

    except Exception as e:
        print(f"ç‰¹å¾æå–å¤±è´¥: {e}")
        return None

def calculate_balanced_similarity(features1, features2):
    """å¹³è¡¡çš„ç›¸ä¼¼åº¦è®¡ç®—"""
    try:
        if not features1 or not features2 or len(features1) != len(features2):
            return 0.0

        n_features = len(features1)

        # 1. è®¡ç®—å½’ä¸€åŒ–çš„æ¬§æ°è·ç¦»
        squared_diff_sum = 0
        for i in range(n_features):
            diff = features1[i] - features2[i]
            squared_diff_sum += diff * diff

        euclidean_distance = math.sqrt(squared_diff_sum) / math.sqrt(n_features)

        # 2. è®¡ç®—æ›¼å“ˆé¡¿è·ç¦»
        manhattan_distance = sum(abs(features1[i] - features2[i]) for i in range(n_features)) / n_features

        # 3. è®¡ç®—ç›¸å…³ç³»æ•°
        mean1 = sum(features1) / n_features
        mean2 = sum(features2) / n_features

        numerator = sum((features1[i] - mean1) * (features2[i] - mean2) for i in range(n_features))

        sum_sq1 = sum((features1[i] - mean1) ** 2 for i in range(n_features))
        sum_sq2 = sum((features2[i] - mean2) ** 2 for i in range(n_features))

        correlation = 0
        if sum_sq1 > 0 and sum_sq2 > 0:
            correlation = numerator / math.sqrt(sum_sq1 * sum_sq2)

        # 4. è·ç¦»åˆ°ç›¸ä¼¼åº¦çš„è½¬æ¢ï¼ˆæ›´æ¸©å’Œï¼‰
        # åŸºäºå®é™…æµ‹è¯•è°ƒæ•´è¿™äº›å‚æ•°
        max_euclidean = 40    # é™ä½é˜ˆå€¼
        max_manhattan = 60    # é™ä½é˜ˆå€¼

        euclidean_sim = max(0, 1 - euclidean_distance / max_euclidean)
        manhattan_sim = max(0, 1 - manhattan_distance / max_manhattan)
        correlation_sim = (correlation + 1) / 2  # å°†-1åˆ°1æ˜ å°„åˆ°0åˆ°1

        # ç»¼åˆç›¸ä¼¼åº¦
        final_similarity = (
            euclidean_sim * 0.4 +
            manhattan_sim * 0.3 +
            correlation_sim * 0.3
        )

        # æ¸©å’Œçš„éçº¿æ€§å˜æ¢
        final_similarity = math.sqrt(final_similarity)  # å¼€æ–¹è€Œä¸æ˜¯ç«‹æ–¹

        return max(0.0, min(1.0, final_similarity))

    except Exception as e:
        print(f"ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
        return 0.0

# å†…å­˜ä¼˜åŒ–ï¼šLCDæ˜¾ç¤ºå‡½æ•°
def safe_lcd_display(img, text_lines, face_rect=None, rect_color=(255, 255, 255)):
    """å®‰å…¨çš„LCDæ˜¾ç¤ºå‡½æ•°ï¼Œé¿å…å†…å­˜æ³„æ¼"""
    try:
        # ç›´æ¥åœ¨åŸå›¾ä¸Šç»˜åˆ¶ï¼Œé¿å…å¤åˆ¶
        y_offset = 5
        for text, color in text_lines:
            img.draw_string(5, y_offset, text, color=color, scale=2)
            y_offset += 20

        # ç»˜åˆ¶äººè„¸æ¡†
        if face_rect:
            img.draw_rectangle(face_rect, color=rect_color, thickness=2)

        # æ˜¾ç¤ºåˆ°LCD
        lcd.display(img)

        # ç«‹å³æ¸…ç†
        gc.collect()

    except Exception as e:
        print(f"LCDæ˜¾ç¤ºå¼‚å¸¸: {e}")
        gc.collect()

def lcd_turn_off():
    """LCDç†„å± - æ˜¾ç¤ºé»‘å±"""
    try:
        # åˆ›å»ºä¸€ä¸ªå…¨é»‘çš„å›¾åƒ
        black_img = image.Image(sensor.width(), sensor.height(), sensor.RGB565)
        black_img.clear()  # æ¸…ç©ºä¸ºé»‘è‰²
        lcd.display(black_img)
        del black_img
        gc.collect()
        print("LCDå±å¹•å·²ç†„ç­")
    except Exception as e:
        print(f"LCDç†„å±å¤±è´¥: {e}")
        gc.collect()

def lcd_wake_up():
    """LCDå”¤é†’ - é‡æ–°åˆå§‹åŒ–"""
    try:
        # LCDé‡æ–°åˆå§‹åŒ–å·²ç»åœ¨ä¸»å¾ªç¯ä¸­å¤„ç†
        print("LCDå±å¹•å·²å”¤é†’")
    except Exception as e:
        print(f"LCDå”¤é†’å¤±è´¥: {e}")
        gc.collect()

def turn_off_all_leds():
    """å…³é—­æ‰€æœ‰LED"""
    red_led.off()
    green_led.off()
    blue_led.off()  # æ·»åŠ è“è‰²LEDå…³é—­

def set_led_status(status):
    """è®¾ç½®LEDçŠ¶æ€
    status: 'success' - ç»¿ç¯, 'fail' - çº¢ç¯, 'uncertain' - é»„ç¯, 'blue' - è“ç¯, 'off' - å…¨éƒ¨å…³é—­
    """
    turn_off_all_leds()
    if status == 'success':
        green_led.on()
    elif status == 'fail':
        red_led.on()
    elif status == 'uncertain':
        red_led.on()
        green_led.on()
    elif status == 'blue':
        blue_led.on()
    # 'off' çŠ¶æ€å·²ç»é€šè¿‡ turn_off_all_leds() å¤„ç†

# === å½•å…¥é˜¶æ®µ ===
print("å¼€å§‹å½•å…¥é˜¶æ®µï¼Œå…±æ‹æ‘„6å¼ ç…§ç‰‡ï¼š\n1. ä¿æŒæ­£è„¸æœå‘é•œå¤´\n2. ä¿æŒé™æ­¢\n3. ä¿æŒå…‰çº¿å……è¶³ä¸”å‡åŒ€")
for user_id in range(num_users_to_enroll):
    username = "ç”¨æˆ·" + str(user_id + 1)
    print(f"\nå¼€å§‹å½•å…¥ {username}")

    user_face_data = {
        "name": username,
        "faces": []
    }

    face_count = 0
    while face_count < faces_per_user:
        print(f"æ‹æ‘„ç¬¬ {face_count + 1} å¼ ç…§ç‰‡...")
        time.sleep(2)

        attempt_count = 0
        face_captured = False

        while not face_captured and attempt_count < 30:
            try:
                # å¼ºåˆ¶å†…å­˜æ¸…ç†
                gc.collect()

                img = sensor.snapshot()

                # ä¼˜åŒ–ï¼šå‡å°‘æ–‡æœ¬ä¿¡æ¯ï¼Œç›´æ¥åœ¨åŸå›¾ä¸Šç»˜åˆ¶
                text_lines = [
                    (f"å½•å…¥: {username}", (255, 255, 255)),
                    (f"ç…§ç‰‡ {face_count + 1}/{faces_per_user}", (255, 255, 255))
                ]

                faces = img.find_features(face_cascade, threshold=0.5, scale_factor=1.25)
                attempt_count += 1

                if faces:
                    largest_face = max(faces, key=lambda f: f[2] * f[3])
                    x, y, w, h = largest_face

                    if w >= 24 and h >= 24:
                        print(f"æ£€æµ‹åˆ°äººè„¸: {w}x{h}")

                        face_roi = img.copy(roi=(x, y, w, h))
                        features = extract_simple_features(face_roi)

                        if features and len(features) > 40:
                            user_face_data["faces"].append(features)
                            print(f"ç¬¬ {face_count + 1} å¼ ç…§ç‰‡ä¿å­˜æˆåŠŸ! ç‰¹å¾æ•°: {len(features)}")

                            # æˆåŠŸæ˜¾ç¤º
                            text_lines.append(("ç…§ç‰‡å·²ä¿å­˜!", (0, 255, 0)))
                            safe_lcd_display(img, text_lines, largest_face, (0, 255, 0))

                            face_captured = True
                            face_count += 1
                        else:
                            print("ç‰¹å¾æå–å¤±è´¥æˆ–ç‰¹å¾ä¸è¶³")
                            text_lines.append(("ç‰¹å¾æå–å¤±è´¥", (255, 0, 0)))
                            safe_lcd_display(img, text_lines, largest_face, (255, 0, 0))

                        del face_roi
                        gc.collect()
                    else:
                        print(f"äººè„¸è¿‡å°: {w}x{h}")
                        text_lines.append(("äººè„¸è¿‡å°", (255, 0, 0)))
                        safe_lcd_display(img, text_lines, largest_face, (255, 0, 0))
                else:
                    if attempt_count % 5 == 0:
                        print(f"å°è¯• {attempt_count}: æœªæ£€æµ‹åˆ°äººè„¸")
                    text_lines.append(("è¯·é¢å‘æ‘„åƒå¤´", (255, 255, 0)))
                    safe_lcd_display(img, text_lines)

                # ç«‹å³åˆ é™¤å›¾åƒå¯¹è±¡
                del img
                gc.collect()

            except Exception as e:
                print(f"å½•å…¥å¼‚å¸¸: {e}")
                gc.collect()

            time.sleep_ms(100)

    user_faces.append(user_face_data)
    print(f"{username} å½•å…¥å®Œæˆ! å…± {len(user_face_data['faces'])} å¼ ç…§ç‰‡")

    # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªç”¨æˆ·å½•å…¥å®Œæˆï¼Œç‚¹äº®è“LEDå¹¶ä¿æŒ2ç§’
    if user_id == 0:  # ç¬¬ä¸€ä¸ªç”¨æˆ· (ç´¢å¼•ä¸º0)
        print("ç¬¬ä¸€ä¸ªç”¨æˆ·å½•å…¥å®Œæˆï¼Œç‚¹äº®è“è‰²LED")
        set_led_status('blue')
        time.sleep(2)  # ä¿æŒ2ç§’
        print("è“è‰²LEDç†„ç­ï¼Œå‡†å¤‡å½•å…¥ä¸‹ä¸€ä¸ªç”¨æˆ·")
        set_led_status('off')

    gc.collect()

print(f"\nå½•å…¥é˜¶æ®µå®Œæˆ! å…±å½•å…¥ {len(user_faces)} ä½ç”¨æˆ·")

# å…¨éƒ¨ç”¨æˆ·å½•å…¥å®Œæˆï¼Œç‚¹äº®è“LEDå¹¶ä¿æŒ2ç§’
print("å…¨éƒ¨ç”¨æˆ·å½•å…¥å®Œæˆï¼Œç‚¹äº®è“è‰²LED")
set_led_status('blue')
time.sleep(2)  # ä¿æŒ2ç§’
print("è“è‰²LEDç†„ç­ï¼Œå¼€å§‹è®¡ç®—è¯†åˆ«åŸºçº¿")
set_led_status('off')

# è®¡ç®—ç”¨æˆ·å†…éƒ¨ç›¸ä¼¼åº¦åŸºçº¿
print("\nè®¡ç®—è¯†åˆ«åŸºçº¿...")
intra_user_similarities = []

for user in user_faces:
    user_similarities = []
    faces = user["faces"]

    for i in range(len(faces)):
        for j in range(i + 1, len(faces)):
            sim = calculate_balanced_similarity(faces[i], faces[j])
            user_similarities.append(sim)

    if user_similarities:
        avg_sim = sum(user_similarities) / len(user_similarities)
        min_sim = min(user_similarities)
        max_sim = max(user_similarities)

        print(f"{user['name']} å†…éƒ¨ç›¸ä¼¼åº¦: å¹³å‡={avg_sim:.3f}, èŒƒå›´=[{min_sim:.3f}, {max_sim:.3f}]")
        intra_user_similarities.extend(user_similarities)

if intra_user_similarities:
    baseline_similarity = sum(intra_user_similarities) / len(intra_user_similarities)
    min_baseline = min(intra_user_similarities)
    std_dev = 0
    if len(intra_user_similarities) > 1:
        variance = sum((s - baseline_similarity) ** 2 for s in intra_user_similarities) / len(intra_user_similarities)
        std_dev = math.sqrt(variance)

    print(f"ç³»ç»ŸåŸºçº¿: å¹³å‡={baseline_similarity:.3f}, æœ€ä½={min_baseline:.3f}, æ ‡å‡†å·®={std_dev:.3f}")

    # ä¿å®ˆçš„é˜ˆå€¼è®¾ç½®
    recognition_threshold = 0.9  # æ¯”æœ€ä½å†…éƒ¨ç›¸ä¼¼åº¦ä½ä¸€äº›
    reject_threshold = 0.89  # æ‹’ç»é˜ˆå€¼

    print(f"è¯†åˆ«é˜ˆå€¼: {recognition_threshold:.3f}")
    print(f"æ‹’ç»é˜ˆå€¼: {reject_threshold:.3f}")
else:
    recognition_threshold = 0.9
    reject_threshold = 0.89
    print(f"ä½¿ç”¨é»˜è®¤é˜ˆå€¼: è¯†åˆ«={recognition_threshold}, æ‹’ç»={reject_threshold}")

time.sleep(2)

# === è¯†åˆ«é˜¶æ®µ ===
print("\nå¼€å§‹è¯†åˆ«é˜¶æ®µï¼š\n1. ä¿æŒæ­£è„¸æœå‘é•œå¤´\n2. ä¿æŒé™æ­¢\n3. ä¿æŒå…‰çº¿å……è¶³ä¸”å‡åŒ€")
print("ä½¿ç”¨å¹³è¡¡çš„ç‰¹å¾æå–å’Œç›¸ä¼¼åº¦è®¡ç®—")
print(f"è¯†åˆ«é˜ˆå€¼: {recognition_threshold:.3f}, æ‹’ç»é˜ˆå€¼: {reject_threshold:.3f}")
print("LEDæ§åˆ¶: 10såè‡ªåŠ¨ç†„ç­, LCD: 15såå…³é—­æ˜¾ç¤º")
print("-" * 50)

recognition_count = 0
last_recognition_time = 0
last_face_detected_time = time.ticks_ms()  # è®°å½•æœ€åä¸€æ¬¡æ£€æµ‹åˆ°äººè„¸çš„æ—¶é—´
led_status_time = 0  # LEDçŠ¶æ€è®¾ç½®æ—¶é—´
current_led_status = 'off'  # å½“å‰LEDçŠ¶æ€
lcd_active = True  # LCDæ˜¯å¦æ¿€æ´»
clock = time.clock()  # æ·»åŠ FPSè®¡ç®—
lcd_update_counter = 0  # LCDæ›´æ–°è®¡æ•°å™¨ï¼Œé™ä½æ›´æ–°é¢‘ç‡

while True:
    try:
        clock.tick()
        current_time = time.ticks_ms()

        # æ¯éš”å‡ å¸§å¼ºåˆ¶æ¸…ç†ä¸€æ¬¡å†…å­˜
        if lcd_update_counter % 10 == 0:
            gc.collect()

        # æ£€æŸ¥LEDçŠ¶æ€ - 10ç§’åç†„ç­
        if current_led_status != 'off' and time.ticks_diff(current_time, led_status_time) > 10000:
            print("LED 10ç§’åè‡ªåŠ¨ç†„ç­")
            set_led_status('off')
            current_led_status = 'off'

        # æ£€æŸ¥LCDçŠ¶æ€ - 15ç§’åå…³é—­
        if lcd_active and time.ticks_diff(current_time, last_face_detected_time) > 15000:
            print("LCD 15ç§’åå…³é—­æ˜¾ç¤º")
            lcd_turn_off()  # ç†„ç­LCDå±å¹•
            lcd_active = False

        img = sensor.snapshot()

        # å‡†å¤‡æ˜¾ç¤ºæ–‡æœ¬
        text_lines = [
            (f"FPS: {clock.fps():.1f}", (255, 255, 255)),
            ("äººè„¸è¯†åˆ«ç³»ç»Ÿ", (255, 255, 255))
        ]

        faces = img.find_features(face_cascade, threshold=0.5, scale_factor=1.25)

        if faces:
            # æ£€æµ‹åˆ°äººè„¸ï¼Œæ›´æ–°æ—¶é—´æˆ³
            last_face_detected_time = current_time

            # å¦‚æœLCDå…³é—­äº†ï¼Œé‡æ–°å¼€å¯
            if not lcd_active:
                print("æ£€æµ‹åˆ°äººè„¸ï¼Œé‡æ–°æ¿€æ´»LCD")
                lcd_wake_up()
                lcd_active = True

            largest_face = max(faces, key=lambda f: f[2] * f[3])
            x, y, w, h = largest_face

            if current_time - last_recognition_time > 3000:

                if w >= 24 and h >= 24:
                    print(f"\n[{recognition_count + 1}] æ£€æµ‹åˆ°äººè„¸: {w}x{h}")
                    text_lines.append(("æ­£åœ¨è¯†åˆ«...", (255, 255, 0)))

                    # ç«‹å³æ˜¾ç¤ºè¯†åˆ«çŠ¶æ€
                    if lcd_active:
                        safe_lcd_display(img, text_lines, largest_face, (255, 0, 0))

                    current_face_roi = img.copy(roi=(x, y, w, h))
                    current_features = extract_simple_features(current_face_roi)

                    if current_features:
                        print("æ­£åœ¨è¿›è¡Œç‰¹å¾åŒ¹é…...")

                        best_match = None
                        best_score = 0
                        all_results = []

                        for user in user_faces:
                            user_scores = []

                            for face_features in user["faces"]:
                                similarity = calculate_balanced_similarity(current_features, face_features)
                                user_scores.append(similarity)

                            if user_scores:
                                avg_score = sum(user_scores) / len(user_scores)
                                max_score = max(user_scores)

                                all_results.append({
                                    "name": user['name'],
                                    "avg_score": avg_score,
                                    "max_score": max_score,
                                    "scores": user_scores
                                })

                                print(f"  {user['name']}: å¹³å‡={avg_score:.3f}, æœ€é«˜={max_score:.3f}")

                                if avg_score > best_score:
                                    best_score = avg_score
                                    best_match = user["name"]

                        print(f"\n=== è¯†åˆ«ç»“æœ {recognition_count + 1} ===")

                        # æ›´æ–°æ˜¾ç¤ºæ–‡æœ¬ï¼ˆç§»é™¤FPSæ˜¾ç¤ºä»¥èŠ‚çœå†…å­˜ï¼‰
                        text_lines = [("äººè„¸è¯†åˆ«ç³»ç»Ÿ", (255, 255, 255))]

                        # åˆ†å±‚åˆ¤æ–­
                        if best_score >= recognition_threshold:
                            # è¿›ä¸€æ­¥éªŒè¯ï¼šæ£€æŸ¥ä¸€è‡´æ€§
                            best_result = next(r for r in all_results if r["name"] == best_match)
                            high_scores = [s for s in best_result["scores"] if s > reject_threshold]
                            consistency = len(high_scores) / len(best_result["scores"])

                            if consistency >= 0.5:  # è‡³å°‘50%çš„æ ·æœ¬è¶…è¿‡æ‹’ç»é˜ˆå€¼
                                print(f"âœ… èº«ä»½éªŒè¯æˆåŠŸ!")
                                print(f"è¯†åˆ«ç”¨æˆ·: {best_match}")
                                print(f"ç½®ä¿¡åº¦: {best_score:.3f}")
                                print(f"ä¸€è‡´æ€§: {consistency:.2f}")
                                print(f"ğŸ”“ è®¿é—®æˆæƒ!")

                                # è®¾ç½®æˆåŠŸLEDçŠ¶æ€
                                set_led_status('success')
                                current_led_status = 'success'
                                led_status_time = current_time

                                # æˆåŠŸè¯†åˆ«æ˜¾ç¤º
                                text_lines.extend([
                                    (f"æ¬¢è¿ {best_match}!", (0, 255, 0)),
                                    ("è®¿é—®å·²æˆæƒ", (0, 255, 0))
                                ])
                                if lcd_active:
                                    safe_lcd_display(img, text_lines, largest_face, (0, 255, 0))

                                # å‘é€UARTæ¶ˆæ¯ - ä»…åœ¨äººè„¸è¯†åˆ«æˆåŠŸæ—¶å‘é€
                                try:
                                    str_buffer = "Hello World"
                                    uart.write(str_buffer)
                                    print("UARTæ¶ˆæ¯å·²å‘é€: Hello World")
                                except Exception as uart_error:
                                    print(f"UARTå‘é€å¤±è´¥: {uart_error}")

                            else:
                                print(f"âš ï¸ è¯†åˆ«ç»“æœä¸ç¨³å®š")
                                print(f"æœ€ç›¸ä¼¼: {best_match} (ç½®ä¿¡åº¦: {best_score:.3f})")
                                print(f"ä¸€è‡´æ€§ä¸è¶³: {consistency:.2f} < 0.5")
                                print("ğŸ”’ æ‹’ç»è®¿é—® - ç»“æœä¸ç¨³å®š")

                                # è®¾ç½®ä¸ç¡®å®šLEDçŠ¶æ€
                                set_led_status('uncertain')
                                current_led_status = 'uncertain'
                                led_status_time = current_time

                                # ä¸ç¨³å®šæ˜¾ç¤º
                                text_lines.extend([
                                    ("è¯†åˆ«ä¸ç¨³å®š", (255, 255, 0)),
                                    ("è¯·é‡æ–°å°è¯•", (255, 255, 0))
                                ])
                                if lcd_active:
                                    safe_lcd_display(img, text_lines, largest_face, (255, 255, 0))

                        elif best_score >= reject_threshold:
                            print(f"âš ï¸ å¯èƒ½æ˜¯å·²çŸ¥ç”¨æˆ·ä½†ç½®ä¿¡åº¦ä¸è¶³")
                            print(f"æœ€ç›¸ä¼¼: {best_match} (ç½®ä¿¡åº¦: {best_score:.3f})")
                            print(f"éœ€è¦é‡æ–°å°è¯•æˆ–æ”¹å–„æ‹æ‘„æ¡ä»¶")
                            print("ğŸ”’ ä¸´æ—¶æ‹’ç»è®¿é—®")

                            # è®¾ç½®ä¸ç¡®å®šLEDçŠ¶æ€
                            set_led_status('uncertain')
                            current_led_status = 'uncertain'
                            led_status_time = current_time

                            # ç½®ä¿¡åº¦ä¸è¶³æ˜¾ç¤º
                            text_lines.extend([
                                ("ç½®ä¿¡åº¦ä¸è¶³", (255, 255, 0)),
                                ("è¯·é‡æ–°å°è¯•", (255, 255, 0))
                            ])
                            if lcd_active:
                                safe_lcd_display(img, text_lines, largest_face, (255, 255, 0))

                        else:
                            print(f"âŒ æœªè¯†åˆ«å‡ºå·²çŸ¥ç”¨æˆ·")
                            if best_match:
                                print(f"æœ€ç›¸ä¼¼: {best_match} (ç½®ä¿¡åº¦: {best_score:.3f})")
                            print("ğŸ”’ æ‹’ç»è®¿é—® - æœªæˆæƒäººå‘˜")

                            # è®¾ç½®å¤±è´¥LEDçŠ¶æ€
                            set_led_status('fail')
                            current_led_status = 'fail'
                            led_status_time = current_time

                            # æ‹’ç»è®¿é—®æ˜¾ç¤º
                            text_lines.extend([
                                ("è®¿é—®è¢«æ‹’ç»", (255, 0, 0)),
                                ("æœªæˆæƒäººå‘˜", (255, 0, 0))
                            ])
                            if lcd_active:
                                safe_lcd_display(img, text_lines, largest_face, (255, 0, 0))

                        recognition_count += 1
                        last_recognition_time = current_time

                        print("-" * 50)
                    else:
                        print("âš ï¸ ç‰¹å¾æå–å¤±è´¥")
                        text_lines.append(("ç‰¹å¾æå–å¤±è´¥", (255, 0, 0)))
                        if lcd_active:
                            safe_lcd_display(img, text_lines, largest_face, (255, 0, 0))

                    del current_face_roi
                    gc.collect()
                else:
                    print(f"âš ï¸ äººè„¸å°ºå¯¸ä¸è¶³: {w}x{h}")
                    text_lines.append(("äººè„¸è¿‡å°", (255, 0, 0)))
                    if lcd_active:
                        safe_lcd_display(img, text_lines, largest_face, (255, 0, 0))
            else:
                # ç­‰å¾…çŠ¶æ€ - é™ä½æ›´æ–°é¢‘ç‡
                if lcd_active and lcd_update_counter % 5 == 0:  # æ¯5å¸§æ›´æ–°ä¸€æ¬¡
                    text_lines.append(("è¯·ç¨å€™...", (255, 255, 255)))
                    safe_lcd_display(img, text_lines, largest_face, (255, 0, 0))
        else:
            # æœªæ£€æµ‹åˆ°äººè„¸
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å…³é—­LEDï¼ˆè¶…è¿‡10ç§’ï¼‰
            if current_led_status != 'off' and time.ticks_diff(current_time, last_face_detected_time) > 10000:
                if current_led_status != 'off':  # é¿å…é‡å¤è¾“å‡º
                    print("10ç§’æœªæ£€æµ‹åˆ°äººè„¸ï¼Œå…³é—­LED")
                    set_led_status('off')
                    current_led_status = 'off'

            # ç­‰å¾…æ£€æµ‹äººè„¸ - é™ä½æ›´æ–°é¢‘ç‡
            if lcd_active and lcd_update_counter % 3 == 0:  # æ¯3å¸§æ›´æ–°ä¸€æ¬¡
                text_lines.append(("ç­‰å¾…æ£€æµ‹äººè„¸", (255, 255, 255)))
                safe_lcd_display(img, text_lines)

        # ç«‹å³åˆ é™¤å›¾åƒå¯¹è±¡
        del img
        gc.collect()

        lcd_update_counter += 1

    except KeyboardInterrupt:
        print("\nç¨‹åºç»ˆæ­¢")
        break
    except Exception as e:
        print(f"è¯†åˆ«å¼‚å¸¸: {e}")
        gc.collect()

    time.sleep_ms(50)

print("\näººè„¸è¯†åˆ«ç³»ç»Ÿå…³é—­")
# æ¸…ç†èµ„æº
turn_off_all_leds()
if lcd_active:
    lcd_turn_off()
gc.collect()
